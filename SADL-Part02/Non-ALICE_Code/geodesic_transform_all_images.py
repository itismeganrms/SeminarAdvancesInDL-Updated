# -*- coding: utf-8 -*-
"""geodesic_transform_Sherry.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DpkWVFoaih02n7dEM12qhXj9tkMe8moK
"""

!pip install nibabel
!pip install SimpleITK
!pip install monai
!pip install timm

from google.colab import drive
drive.mount('/content/drive')

import os

# Define the root directory pointing to your BRATS dataset
root_dir = "/content/drive/My Drive/BRATS/MICCAI_BraTS2020_TrainingData"

# Change to that directory (optional, only if you want to work from there)
os.chdir(root_dir)

# List the files/folders inside the dataset directory
!ls

def merge_seg(seg_path):
    seg, _ = get_data(seg_path, is_seg=True)
    combined_seg = [(seg == 1) | (seg == 4), (seg == 1) | (seg == 4) | (seg == 2), seg == 4]
    combined_seg = np.stack(combined_seg, axis=0)
    return combined_seg

def get_data(input_name, is_seg=False):

    if not os.path.isfile(input_name):
        print("File not exists:", input_name)
        return -1

    img = sitk.ReadImage(input_name)
    np_img = sitk.GetArrayFromImage(img)
    spacing_raw = img.GetSpacing()
    if is_seg:
        return np.asarray(np_img, np.uint8), spacing_raw
    else:
        return np.asarray(np_img, np.float32), spacing_raw

import torch
import nibabel as nib
import numpy as np
from pathlib import Path
import os


def transform_geo_dist(dist, gt, label_name):
    margin = 0.5

    def _transform_layer(dist_layer, gt_layer):
        fg = (gt_layer == 1)
        bg = (gt_layer == 0)
        #dist_layer[bg] = torch.clamp_min(dist_layer[bg], -fg_max)
        dist_layer[fg] = torch.clamp_min(dist_layer[fg], 0.0)
        dist_layer[bg] = torch.clamp_max(dist_layer[bg], 0.0)

        if torch.sum(fg) == 0:
            return torch.full_like(dist_layer, -1)

        fg_max = dist_layer[fg].max()
        dist_layer[bg] = torch.clamp_min(dist_layer[bg], -fg_max)

        dist_layer = dist_layer / (fg_max + 1e-8)

        if label_name == "fast_sgc_margin":
            dist_layer[fg] = dist_layer[fg] * (1.0 - margin) + margin
            dist_layer[bg] = dist_layer[bg] * (1.0 - margin) - margin

        dist_layer = torch.clamp(dist_layer, -1.0, 1.0)

        if label_name == "fast_sgc_clamp":
            dist_layer[(gt_layer > 0) & (dist_layer <= 0)] = dist_layer[dist_layer > 0.0001].min()
            dist_layer[(gt_layer == 0) & (dist_layer >= 0)] = dist_layer[dist_layer < -0.0001].max()

        return dist_layer

    for i in range(dist.shape[-1]):
        dist[..., i] = _transform_layer(dist[..., i], gt[..., i])
    return dist


def transform_gd_dist(dist, gt):
    def _transform_gd_dist_layer(dist_layer, gt_layer):
        # Ensure the shapes match and masks are boolean
        #assert dist_layer.shape == gt_layer.shape, "Shape mismatch!"

        fg = (gt_layer == 1)
        bg = (gt_layer == 0)

        dist_layer[fg] = torch.clamp_min(dist_layer[fg], 0.52)
        dist_layer[bg] = torch.clamp_max(dist_layer[bg], 0.48)

        return dist_layer

    # Sanity check for NaNs before processing
    #assert not torch.any(torch.isnan(dist)), "NaNs found in input distance tensor"

    # Loop over the last dimension (D)


    #if gt.ndim == 4 and gt.shape[-1] == 1:
    #new_gt = gt.squeeze(-1)
    gt = gt[..., 0]
    #print(f"new_gt.shape: {new_gt.shape}")
    print(f"gt.shape: {gt.shape}")


    for index in range(dist.shape[-1]):
        dist_layer = dist[..., index]
        gt_layer = gt[..., index]

        print("dist_layer shape:", dist_layer.shape)
        print("gt_layer shape:", gt_layer.shape)
        #print("fg dtype:", fg.dtype, "shape:", fg.shape)


        # Apply per-layer transformation
        dist[..., index] = _transform_gd_dist_layer(dist_layer, gt_layer)

    # Sanity check after processing
    assert not torch.any(torch.isnan(dist)), "NaNs introduced during transformation"

    return dist



def process_single_image(image_path, gt_path, output_path, label_name="fast_sgc_margin", dataset="BRATS", device="cpu"):
    print(f"Processing {image_path.name}")
    hard_gt_path = gt_path

    if dataset == "BRATS":
        #from your_custom_module import merge_seg  # replace with
        hard_gt = np.transpose(merge_seg(hard_gt_path), [3, 2, 1, 0])#your actual function
        #hard_gt = np.transpose(merge_seg(gt_path), [3, 2, 1, 0])
        #print(gt_path)
        #hard_gt = merge_seg(gt_path)
        #print(hard_gt)
    else:
        #from your_custom_module import get_data  # replace with your actual function
        hard_gt = get_data(gt_path, is_seg=True)[0]
        hard_gt = np.transpose(np.expand_dims(hard_gt, 0), [3, 2, 1, 0])

    hard_gt = torch.tensor(hard_gt, device=device)
    raw_geo = nib.load(image_path).get_fdata()
    geo_tensor = torch.tensor(raw_geo, device=device)

    if label_name == "gd_normed":
        transformed = transform_gd_dist(geo_tensor, hard_gt)
        print(f"transformed: {transformed}")
    else:
        transformed = transform_geo_dist(geo_tensor, hard_gt, label_name)

    result_np = transformed.cpu().numpy()
    print(f"RESULTS_NP: {result_np}")
    #result_np = np.transpose(result_np, [3, 2, 1, 0])
    print(f"output_path : {output_path}")
    os.makedirs(output_path.parent, exist_ok=True)
    nib.save(nib.Nifti1Image(result_np, affine=np.eye(4)), output_path)
    print(f"Saved to {output_path}")

def split_dataset(root_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):
    """Splits the dataset into training, validation, and test sets.

    Args:
        root_dir: The root directory of the dataset.
        train_ratio: The proportion of the dataset to include in the training split.
        val_ratio: The proportion of the dataset to include in the validation split.
        test_ratio: The proportion of the dataset to include in the test split.
    """

    if train_ratio + val_ratio + test_ratio != 1.0:
        raise ValueError("The sum of train_ratio, val_ratio, and test_ratio must be 1.0")

    cases = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]
    random.shuffle(cases)  # Shuffle cases for randomness

    num_cases = len(cases)
    num_train = int(num_cases * train_ratio)
    num_val = int(num_cases * val_ratio)
    num_test = num_cases - num_train - num_val  # Ensure all cases are used

    train_cases = cases[:num_train]
    val_cases = cases[num_train:num_train + num_val]
    test_cases = cases[num_train + num_val:]

    splits = {"train": train_cases, "val": val_cases, "test": test_cases}

    for split_name, case_list in splits.items():
        output_dir = Path(root_dir) / split_name
        output_dir.mkdir(exist_ok=True)
        for case_name in case_list:
            source_dir = Path(root_dir) / case_name
            destination_dir = output_dir / case_name
            shutil.copytree(source_dir, destination_dir, dirs_exist_ok=True)
            print(f"Moved {case_name} to {destination_dir}")


def visualize_slice(image_path, slice_index=50):
    img = nib.load(str(image_path))
    data = img.get_fdata()

    # Ensure slice_index doesn't exceed dimensions
    slice_index = min(slice_index, data.shape[2] - 1)
    slice_data = data[:, :, slice_index]

    plt.imshow(slice_data.T, cmap='gray', origin='lower')
    plt.title(f"{image_path.parent.name} - {image_path.name} (Slice {slice_index})")
    plt.axis('off')
    plt.show()

import os
from pathlib import Path
import SimpleITK as sitk

def process_single_image(image_path, output_path):
    """
    Dummy processor: simply reads and writes the image as-is.
    You can add actual preprocessing steps here.
    """
    print(f"Processing {image_path.name} -> {output_path}")
    image = sitk.ReadImage(str(image_path))
    sitk.WriteImage(image, str(output_path))

if __name__ == "__main__":
    #DO GEODESIC TRANSFORM
    dataset = "BRATS"
    input_folder = Path("/content/drive/My Drive/BRATS/MICCAI_BraTS2020_TrainingData")
    output_root = input_folder / "results"
    output_root.mkdir(exist_ok=True)

    suffixes = ["_t1.nii", "_t1ce.nii", "_seg.nii", "_flair.nii", "_t2.nii"]

    for case_dir in input_folder.iterdir():
        if case_dir.is_dir() and case_dir.name.startswith("BraTS20_Training_"):
            case_id = case_dir.name
            output_case_dir = output_root / case_id
            output_case_dir.mkdir(exist_ok=True)

            for suffix in suffixes:
                image_file = case_dir / f"{case_id}{suffix}"
                if image_file.exists():
                    output_file = output_case_dir / f"{case_id}{suffix.replace('.nii', '_transformed.nii.gz')}"
                    process_single_image(image_file, output_file)

    # SPLIT THE DATASET
    root_dir = "/content/drive/My Drive/BRATS/MICCAI_BraTS2020_TrainingData" #Replace with the actual path
    split_dataset(root_dir)

# prompt: split the images into a training set, validation set and test set

import os
import random
import shutil
from pathlib import Path


'''

if __name__ == "__main__":
    root_dir = "/content/drive/My Drive/BRATS/MICCAI_BraTS2020_TrainingData" #Replace with the actual path
    split_dataset(root_dir)

import matplotlib.pyplot as plt
import nibabel as nib
import numpy as np
from pathlib import Path

# Root folder containing result subfolders
output_folder = Path("/content/drive/My Drive/BRATS/MICCAI_BraTS2020_TrainingData/results")



# Get list of case directories in results
sample_dirs = sorted([d for d in output_folder.iterdir() if d.is_dir()])[:2]  # First 2 samples

# Visualize all transformed images for each sample
for sample_dir in sample_dirs:
    print(f"\nüìÅ Visualizing for: {sample_dir.name}")
    for image_path in sorted(sample_dir.glob("*_transformed.nii.gz")):
        visualize_slice(image_path, slice_index=50)

        FOR VISUALIZATION


python geodesic_transform.py --label_name "fast_sgc_margin" 
      --dataset ${BRATS} \
      --root_dir ${Semantic-Segmentation} 
      --gt_dir ${Semantic-Segmentation} 
      --output_dir ${Semantic-Segmentation}


'''