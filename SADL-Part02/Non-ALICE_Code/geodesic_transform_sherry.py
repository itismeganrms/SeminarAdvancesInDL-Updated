# -*- coding: utf-8 -*-
"""geodesic_transform_Sherry.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DpkWVFoaih02n7dEM12qhXj9tkMe8moK
"""

!pip install nibabel
!pip install SimpleITK

from google.colab import drive
drive.mount('/content/drive')

import os

# Define the root directory pointing to your BRATS dataset
root_dir = "/content/drive/My Drive/BRATS/MICCAI_BraTS2020_TrainingData"

# Change to that directory (optional, only if you want to work from there)
os.chdir(root_dir)

# List the files/folders inside the dataset directory
!ls

# prompt: distance between point a and b

import numpy as np

def distance(point_a, point_b):
  """Calculates the Euclidean distance between two points.

  Args:
    point_a: A tuple or list representing the coordinates of point A.
    point_b: A tuple or list representing the coordinates of point B.

  Returns:
    The Euclidean distance between point A and point B.
  """
  return np.linalg.norm(np.array(point_a) - np.array(point_b))


# Example usage
point_a = (1, 2, 3)
point_b = (4, 5, 6)
dist = distance(point_a, point_b)
print(f"The distance between {point_a} and {point_b} is: {dist}")

def merge_seg(seg_path):
    seg, _ = get_data(seg_path, is_seg=True)
    combined_seg = [(seg == 1) | (seg == 4), (seg == 1) | (seg == 4) | (seg == 2), seg == 4]
    combined_seg = np.stack(combined_seg, axis=0)
    return combined_seg

def get_data(input_name, is_seg=False):

    if not os.path.isfile(input_name):
        print("File not exists:", input_name)
        return -1

    img = sitk.ReadImage(input_name)
    np_img = sitk.GetArrayFromImage(img)
    spacing_raw = img.GetSpacing()
    if is_seg:
        return np.asarray(np_img, np.uint8), spacing_raw
    else:
        return np.asarray(np_img, np.float32), spacing_raw

import torch
import nibabel as nib
import numpy as np
from pathlib import Path
import os


def transform_geo_dist(dist, gt, label_name):
    margin = 0.5

    def _transform_layer(dist_layer, gt_layer):
        fg = (gt_layer == 1)
        bg = (gt_layer == 0)
        #dist_layer[bg] = torch.clamp_min(dist_layer[bg], -fg_max)
        dist_layer[fg] = torch.clamp_min(dist_layer[fg], 0.0)
        dist_layer[bg] = torch.clamp_max(dist_layer[bg], 0.0)

        if torch.sum(fg) == 0:
            return torch.full_like(dist_layer, -1)

        fg_max = dist_layer[fg].max()
        dist_layer[bg] = torch.clamp_min(dist_layer[bg], -fg_max)

        dist_layer = dist_layer / (fg_max + 1e-8)

        if label_name == "fast_sgc_margin":
            dist_layer[fg] = dist_layer[fg] * (1.0 - margin) + margin
            dist_layer[bg] = dist_layer[bg] * (1.0 - margin) - margin

        dist_layer = torch.clamp(dist_layer, -1.0, 1.0)

        if label_name == "fast_sgc_clamp":
            dist_layer[(gt_layer > 0) & (dist_layer <= 0)] = dist_layer[dist_layer > 0.0001].min()
            dist_layer[(gt_layer == 0) & (dist_layer >= 0)] = dist_layer[dist_layer < -0.0001].max()

        return dist_layer

    for i in range(dist.shape[-1]):
        dist[..., i] = _transform_layer(dist[..., i], gt[..., i])
    return dist

'''
def transform_gd_dist(dist, gt):
    def _transform_layer(dist_layer, gt_layer):
        fg = (gt_layer == 1)

        bg = (gt_layer == 0)
        print(f"dist_layer: {dist_layer}")
        print(f"dist_layer shape: {dist_layer.shape}")
        print(f"fg: {fg}")
        print(f"bg: {bg}")
        fg = fg.bool()
        bg = bg.bool()

        print("dist_layer shape:", dist_layer.shape)
        print("gt_layer shape:", gt_layer.shape)
        print("fg dtype:", fg.dtype, "shape:", fg.shape)


        #dist_layer[bg] = torch.clamp_min(dist_layer[bg], -fg)

        dist_layer[fg] = torch.clamp_min(dist_layer[fg], 0.52)
        dist_layer[bg] = torch.clamp_max(dist_layer[bg], 0.48)
        return dist_layer

    for i in range(dist.shape[-1]):
        dist[..., i] = _transform_layer(dist[..., i], gt[..., i])
    return dist
'''

def transform_gd_dist(dist, gt):
    def _transform_gd_dist_layer(dist_layer, gt_layer):
        # Ensure the shapes match and masks are boolean
        #assert dist_layer.shape == gt_layer.shape, "Shape mismatch!"

        fg = (gt_layer == 1)
        bg = (gt_layer == 0)

        dist_layer[fg] = torch.clamp_min(dist_layer[fg], 0.52)
        dist_layer[bg] = torch.clamp_max(dist_layer[bg], 0.48)

        return dist_layer

    # Sanity check for NaNs before processing
    #assert not torch.any(torch.isnan(dist)), "NaNs found in input distance tensor"

    # Loop over the last dimension (D)


    #if gt.ndim == 4 and gt.shape[-1] == 1:
    #new_gt = gt.squeeze(-1)
    gt = gt[..., 0]
    #print(f"new_gt.shape: {new_gt.shape}")
    print(f"gt.shape: {gt.shape}")


    for index in range(dist.shape[-1]):
        dist_layer = dist[..., index]
        gt_layer = gt[..., index]

        print("dist_layer shape:", dist_layer.shape)
        print("gt_layer shape:", gt_layer.shape)
        #print("fg dtype:", fg.dtype, "shape:", fg.shape)


        # Apply per-layer transformation
        dist[..., index] = _transform_gd_dist_layer(dist_layer, gt_layer)

    # Sanity check after processing
    assert not torch.any(torch.isnan(dist)), "NaNs introduced during transformation"

    return dist



def process_single_image(image_path, gt_path, output_path, label_name="fast_sgc_margin", dataset="BRATS", device="cpu"):
    print(f"Processing {image_path.name}")
    hard_gt_path = gt_path

    if dataset == "BRATS":
        #from your_custom_module import merge_seg  # replace with
        hard_gt = np.transpose(merge_seg(hard_gt_path), [3, 2, 1, 0])#your actual function
        #hard_gt = np.transpose(merge_seg(gt_path), [3, 2, 1, 0])
        #print(gt_path)
        #hard_gt = merge_seg(gt_path)
        #print(hard_gt)
    else:
        #from your_custom_module import get_data  # replace with your actual function
        hard_gt = get_data(gt_path, is_seg=True)[0]
        hard_gt = np.transpose(np.expand_dims(hard_gt, 0), [3, 2, 1, 0])

    hard_gt = torch.tensor(hard_gt, device=device)
    raw_geo = nib.load(image_path).get_fdata()
    geo_tensor = torch.tensor(raw_geo, device=device)

    if label_name == "gd_normed":
        transformed = transform_gd_dist(geo_tensor, hard_gt)
        print(f"transformed: {transformed}")
    else:
        transformed = transform_geo_dist(geo_tensor, hard_gt, label_name)

    result_np = transformed.cpu().numpy()
    print(f"RESULTS_NP: {result_np}")
    #result_np = np.transpose(result_np, [3, 2, 1, 0])
    print(f"output_path : {output_path}")
    os.makedirs(output_path.parent, exist_ok=True)
    nib.save(nib.Nifti1Image(result_np, affine=np.eye(4)), output_path)
    print(f"Saved to {output_path}")

import os
from pathlib import Path
import SimpleITK as sitk

def process_single_image(image_path, gt_path, output_path, label_name, dataset, device="cpu"):
    # Dummy implementation for demonstration; replace with your own logic
    print(f"Processing {image_path.name} -> {output_path.name}")
    image = sitk.ReadImage(str(image_path))
    # Process (dummy: just copy image)
    sitk.WriteImage(image, str(output_path))

if __name__ == "__main__":
    label_name = "gd_normed"
    dataset = "BRATS"

    input_folder = Path("/content/drive/My Drive/BRATS/MICCAI_BraTS2020_TrainingData")
    output_folder = input_folder / "results"
    output_folder.mkdir(exist_ok=True)

    for case_dir in input_folder.iterdir():
        if case_dir.is_dir() and case_dir.name.startswith("BraTS20_Training_"):
            seg_file = case_dir / f"{case_dir.name}_seg.nii"
            if seg_file.exists():
                output_path = output_folder / f"{case_dir.name}_transformed.nii.gz"
                process_single_image(seg_file, seg_file, output_path, label_name, dataset, device="cpu")

